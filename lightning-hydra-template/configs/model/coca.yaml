_target_: src.models.coca_module.CocaModule

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.001
  weight_decay: 0.0

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 50

net:
  _target_: CoCa_pytorch.coca_pytorch.coca_pytorch.CoCa
  dim: 512                                                              # model dimension
  img_encoder: vit                                                      # vision transformer - image encoder, returning image embeddings as (batch, seq, dim)
  image_dim: 1024                                                       # image embedding dimension, if not the same as model dimensions
  num_tokens: 49408                                                     # number of text tokens
  unimodal_depth: 6                                                     # depth of the unimodal transformer
  multimodal_depth: 6                                                   # depth of the multimodal transformer
  dim_head: 64                                                          # dimension per attention head
  heads: 8                                                              # number of attention heads
  caption_loss_weight: 2.                                               # weight on the autoregressive caption loss
  contrastive_loss_weight: 1.                                           # weight on the contrastive loss between image and te
